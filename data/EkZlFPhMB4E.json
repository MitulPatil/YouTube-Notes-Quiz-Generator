{
  "video_id": "EkZlFPhMB4E",
  "timestamp": "2025-12-15T21:25:09.465741",
  "transcript": "Let me set the context for the video. This video is a highle road map to learn CS in one of four niches. Fullstack, DevOps, AI, and web 3. Um, these are the four niches. It's where it's sort of easy to get an entry- level job and provide value to a company on day zero. If you have gone through the syllabus well, in fact, I've actually built projects that showcase that you're good at one of these four skills. CS generally is a fairly vast field. Um, and you can go very deep into, you know, learning various concepts of CS. But these are the ones that require engineers and, you know, require basically human labor. um to be able to execute fast in a company, which is why these are good niches to pick um in case you're looking for a immediate job in the next, you know, 3 months, 6 months, whatever that timeline is for you. Um generally though, if you're just starting out, it'll probably take you 6 to 8 months to get decent at one of these niches. Um I would also suggest if you are just starting out, then probably just stick to full stack. But if you are, you know, if you've done a little bit of CS, you already have a job, uh you're in college, but you have a decent DSA, then you can probably pick up other things. If you're a complete beginner, probably just stick to full stack and, you know, go from there. With that, we'll dive right into it. We'll probably kick things off with full stack, which is the simplest one and probably fairly commoditized at this point. I think everyone knows what full stack is and has heard some level of the other of a jargon. I think MS stack is something that's fairly popular/ you know, very easy to target in probably 2 months if you have decent CSIQ. We'll kick things off with that. For full stack development, um, this is how I would learn it and everything that's mentioned over here. You can think of it like a cohort video, you know, a two hour, three hour video that you have to go through. Some of these topics can be broken down into more than one videos. But generally, I think most of these topics are a 3 to four hour followalong video or a grind and then, you know, a bunch of projects/ assignments you can do on top of it. But generally kick things off with HTML, CSS. This is where people spend a little too much time. Uh, but I think one video or you know basically a week is more than enough um to get on with the basics. Then move on to JavaScript because that's where you're going to spend most of your time. Anyways, basics of JavaScript. That's just the syntax. The architecture of JS and async.js are two nice things to do early on. Even though this is probably where you'll feel a little bit of a hunch if you are just a beginner um and if you haven't done any coding before um then maybe feel free to skip through these topics and come back to them later. Then comes the difference between client side and server side JavaScript and you know why there is this difference why serverside JavaScript even introduced um and just understanding the various places you can run JavaScript. HTTP and Express a more generic concept to learn not just you know specific to the MER stack which is the one that we're talking about right now. Um HTTP is a protocol we'll learn many protocols later on. Um but the most popular protocol that you're probably going to hit if you're using any application today like a Zeppto or a PTM or a Blinket any website 99% of the times you're probably hitting an HTTP server. So understanding this protocol makes a lot of sense. Even though there are other protocols to learn this is the one you'll probably spend most of your time building in team. One way to build an HTTP protocol in JavaScript is Express. So very popular framework. It's what E stands for in the stack. Um and hence good for you to get really good at this because you'll probably be interviewed in Express and you know what does one thing do or what does one function do in Express. Basically try to get as hands-on as possible on Express and spend a decent chunk of time here. So this is probably you know probably five classes. If if if you're spending uh 3 days on HTML CSS then probably spend 15 days on Express. then move on to databases and start with MongoDB is the simplest one very easy to digest. There's the reason most people choose MongoDB when they're just starting out because it it hides a lot of complexity from you. You don't have the complexity of learning a new language like SQL. It sort of makes sense to follow this as a beginner. Um but eventually definitely move to something like Postgress or MySQL because most probably a company that you're joining is going to be using a SQL database something like Postgress or SQL and hence when you're once you're done with the basics you've built a few full stack projects at this point move on to learning Postgress really quickly probably understand SQL how to write SQL queries um and then eventually learn about OMS and Prisma and other two ones the popular ones in NodeJS um just pick one of them finish it off and then that's that's your full stack not your full stack that's your backend stack for the day this backend stack can probably build everything that you need. A lot of big companies, small companies that you see are probably written in this stack and if you know up until this point you can probably understand most of their code bases. Um and you know start to provide value to them. It's about I think a lot of topics are important probably needed. So I wouldn't just stop here. TypeScript and bunjs are two topics I would spend a little bit of time on. Um Typescript a lot of time on but basically just understanding how is it different from JavaScript and or NodeJS and why is it being adopted a little more over node. Now turbo repo is sort of the benchmark of creating monor repos or not even monor repos like whatever a build system in JavaScript today. So whenever you open a repo for the first time if you're joining a company or otherwise um you'll probably be hit with a bunch of turbo jargon. So it makes sense to just you know go through it really quickly and then comes you know a little bit of front end. So until this point you're pretty good at back end. Um if you've done all of this well everything from 0.1 to1 then you can build backends fairly well. I think one more thing I would add would be to write tests for your backend applications and then you're a great backend developer. then you should probably move on to front end because most probably a company that's hiring will hire a full start engineer and not a pure back end engineer and it's not very hard of a skill to learn. Um if you've been able to learn everything from 0.1 to1 then 12 is probably not that difficult. Um there's a little bit of a learning curve um but nothing crazy compared to back end. Um so finish off react and tailwind which probably can be good enough like that's when you're a full stack engineer. I'm skipping through a bunch of sub points here though react you can do 10 different things and learn different things. Tailwind probably not like tailwind is fairly simple but react is probably again you know five to six days or classes of an effort before you can actually say you're decent at react with a bunch of subtopics to understand well which I'm not you know noting down over here followed by next in case you want to learn it you you'll be probably be fine without nextjs as well but again a lot of us based startups just have next as a stack as in they don't even use nodejs or express for their back end they create their back end and their front end both in next hence it is a decent stack to know of a few other stacks to point out would be you know something like TRPC the T3 stack Alisa JS is a new framework now there like a lot of new startups will probably always move towards something fancy um and for good reasons like Alisa JS is a faster framework compared to express like significantly faster bun is significantly faster compared to node in a bunch of benchmarks and hence it sort of makes sense why startups are moving there um but if you're decent at NodeJS none of these are very hard to pick up um so if you're decent at react next isn't that hard to pick up unless you really want to you know um get into the nitty-g gritties of how NexJS works in a few very Nexus specific points finally if do feel like learning other protocols other than HTTP which is the most popular one. Then websockets and web TCR2 decent protocols to look at. There are a bunch of other protocols like XMTP, there is serverside events, there is TNET, there is the SMTP protocol. U none of them will probably be needed for an early inciner. Um and hence they're good to know but probably not something you dive too deep into into websockets you probably need to dive mildly deeper into and web I'd say not super necessary for a full stack engineer. And lastly, uh slightly more backend heavy concepts. Cues and popsup are just two of them. There are various ways backends can communicate. The if you know these, you'll probably sort it for 99% of the use cases. And this will just make you a little better at back end. This is not an exhaustive list. Um now that I think about it, this is like a this is like a good list. This is like a good entry level engineer list. This after this, you know, you can probably explore everything. You can probably explore all this on your own as well. But basically if you've done everything from 1 to 16 really well that means you're pretty much good to go to learn anything in the monthstack or you know probably the JavaScript ecosystem is what I mean this will get a little tricky if you move from JavaScript to Java or JavaScript to go or JavaScript to Python. So there are a bunch of other challenges there to discuss. I'm not writing them down here. This is specifically for you know very simple basic one stack engineer. And if you need more topics let me know in the comments uh because I can think of thousand other things to add over here. But if you want a more actionable to the point road map for full stack, I think this is it for in terms of the slaves. In terms of the projects, build a to-do app until the month stack point I think at least one should do this. And if there are 100 people starting full stack, probably 90 would drop off until this point. So only 10, you're only left with 10 after this point who can create a to-do app, a psoringelling app, an e-commerce app, people tend to build this and just stop. Uh which is why you know you you if you do move forward from there the probability of you know success is much higher. So just to build this initially to learn a few things and then I've put out a few here that I primarily feel like are good projects in the sense they touch a lot of these technologies that we've talked about on the left and also they're not very trivial in the sense there is some level of you know something extra that's needed more than full stack. That's pretty much a simple answer there. Okay. The reason a lovable or a quote versus or trading app is slightly better than a to-do app is because they might require you know a protocol like websocket which is point number 15 or you know something like cues which is point number 16 which you probably don't need in a to-do application. It's the simple one. Lav will require you know hitting LM APIs parsing data from there. So it's a little out of the comfort zone. It's a little out of what's already been written on the left which is why I think these are better projects compared to the ones you know mentioned like simple projects like an e-commerce project something like that. Here are a few resources and this channel covers a bunch of this. primary if you'll find resources on one thing it'll be full stuck on this channel might be one good channel to look at agile has a course uh it's a paid course but it's pretty cheap I think it's like 300 rupees on Udemi great for beginners so if you feel like you need a lot of handholding initially you've never done coding I think it's a decent resource react specifically for one thing which is like the react website but I haven't found a a better documentation in the NodeJS ecosystem compared to what's present here so whenever you do reach react I think react is great but again it's probably great for people who don't require a lot of handholding I read it fairly often uh But maybe I wouldn't have been able to digest it when I started React back in 2019 I think. Um so just keep that in mind uh and based on that make a decision. And lastly the best thing you can do which again is less handholdy is look at open source projects. I've I've written them down to two categories which is GSOC organizations which there are a lot of them in JavaScript or the JavaScript ecosystem generally. Um and then open source companies which most of them are written next. Um so if you can read through their code bases try to understand them try to maybe solve an issue or two and you know when I say is solving an issue I mean uh solving a substantial issue an issue that actually provides value to the company that is a good resource to actually learn something because you're not just creating your own projects in your way. you're contributing to a project uh which is being used in production um which is uh probably 100 times better than you know creating something on your own because there's no one to really ridicule you on your code if you're writing code yourself compared to if there is some code that is written already being used in production and you're providing value there um which is why I feel point number four is super necessary but there are a few cautions here one as a beginner very hard to understand code bases two I mean it's probably easy to understand and solve an issue using GPT but if you don't know the points on the left it'll probably make your life very hard and number three um it's easy to spam open source orcs Don't do that. It just creates you know um bad incentives for people to open source in the future. All right with that that's full stack. We move on to the second one. Now I think post fullstack devops is the most obvious choice. Um because if it took you let's say 2 months to learn full stack then it'll probably take you probably another 2 months if you really want to learn DevOps. Well um so let's do that next. Let's get into what uh you need to learn the syllabus of process and the resources for learning DevOps. All right DevOps the slightly harder bit. the really hard to get hired for bit as an early engineer because a very critical bit for a company and no one would want to hire a fresher over here. Um most of the times you grow in DevOps role is by joining a company as a fullstack engineer, front end engineer, back end engineer slowly taking a little bit of ownership and then eventually owning you know more of the codebase sorry not the code base you know the infrastructure um and so basically a caution don't feel like you can get an entry- level job here. If you do get an entry- level job, it's mostly for extremely lowpaying packages because they hire you um to train you for 6 months to a year before they actually give you something critical. The best thing you can do join a company as a full stack engineer and then over there grow as a DevOps engineer and then you can of course move from one company to another. Um if you have some proof of work, there's a very big chicken and egg problem. No one is going to hire you as a DevOps engineer which will lead to you not becoming a DevOps engineer. So the cycle sort of continues. um though you can do a bunch of things but you'll have to spend some money um on a cloud environment you know bringing up resources bringing down resources so make sure you have like $100 on the side um to spend on AWS GCP before you start this we'll kick things off the simplest one this is something you should know generally irrespective of if you're doing um you know DevOps or not uh even if you're doing full stack you need to be fairly decent at the terminal just understanding basic bash commands nothing crazy um which includes you know how do you explore various uh folders, files, create new files, create new folders, open a file, edit a file. If you want to really grind, then feel free to learn vim, neovim, um, and you know, make that your primary uh, coding environment. Uh, generally if you understand most bash commands, um, and are able to, you know, I don't know, push to a git is a good litmus test. If a lot of people don't are not very comfortable with the git cli, um, it's a good litmus test of someone if they've, you know, worked in the terminal or not. So things like this, just make sure you you're able to work through the terminal. uh yourself without GPing a command. Uh I think that would be great. So just go through probably less than a week. Just make sure you just stay in the terminal, try to spend a lot of time there and by the end um you should have enough muscle memory/ you know um will to be able to do things inside the terminal. Learn about VMs and bare metal machines. U I think this is the point where things get slightly fascinating. Uh deploying your code and how does your code get deployed and what are cloud environments. Believe it or not, cloud did not exist until 2008. So people used to actually rent uh you know racks in data centers themselves to be able to deploy their application. Um and now it's fairly abstracted from most humans like you and I. Um but understand the difference between a virtual machine and what a bare metal machine is what happens if you actually go to a data center and um rent a machine compared to um if you get a virtual machine from AWS CCP. What are the performance upsides and downsides in both? But 99% of the times you're going to use a cloud environment you're going to start a virtual machine over here. Um so as long as you understand what a VM is um and how does it actually work under the hood and you know uh what exactly is happening when you go to AWS and create an instance um you're good to go on this section. Um process management plus reverse proxies. This is the most uh vanilla way to deploy an application be the front end or the back end. Um process management basically means making sure if your process crashes you're able to restart it automatically. Reverse proxies are a way for you to deploy multiple applications on the same server which is something you probably want to do early. So a lot of startups, early startups just have one server where they're running their front end, their back end, maybe seven different backends, maybe even the database, which is like fairly dangerous. Um, if a company's doing all of that, um, how can you join that company and understand their infrastructure? How have they deployed their application? Most probably using process management plus proxies. One more thing, very common thing to know is how to generate certificates. What are certificates? How do you move your website from HTTP to HTTPS? Um, and up until this point, I would call the equivalent of this point of full stack. If you understand the mer stack by which I mean if you're able to create a MongoDB database and put some data in it create a a two-do application you're a very basic full stack engineer you basically are fascinated it's like if I start to learn chest if I know all the moves and some very basic you know I'm able to beat someone who's 8800 um the equivalent here would be understanding everything until this point the equivalent in devos would be everything until point 4.5 onwards are a little more you know call them industry ready things slash if a company has hit a certain scale which not enough companies hit scale probably 1% of the companies actually have enough users um to have a need to move from 3 to 0.5 which is um scaling their infrastructure beyond a single machine that means having multiple machines running um and there are many ways to do it the most vanilla one is to either create an autoscaling group in AWS or what are called manage instance groups in GCP every cloud has you know a different name for it but it's basically a bunch of machines that you've started um all of them handling traffic in you know some sort of a round robin fashion so that if you have millions of users hitting your servers um there's not a single virtual machine that's being hit in the end there are multiple machines and it's easy for you to scale up and scale down based on various criterias biggest of the companies um I have a friend who works at Zeppto they use the same thing Zeppto has hit scale right like infinite scale or you know what you'd expect from a very big startup yet they don't have extremely fancy infrastructure they of course don't have point number two which is a single virtual machine but they're also like doing fairly well with you Autoscaling groups, manage groups and you know the life is pretty sorted. They're able to handle handle that scale um with you know a very simple AWS construct called autoscaling groups u which is why it's a great thing for you to know at this point you can join you know midsize to a slightly large size uh startup that has hit scale and needs to serve more than you know 10,000 customers at the same time. Then come again slightly more not needed but important concept. So when I say not needed I mean a startup can probably run without containers but if you are calling yourself a devops engineer most probably the company that you're joining is going to use containers in some form or fashion. What are containers and container runtimes is one concept which is a more Linux specific concept and then what is docker which is a specific container runtime is the second concept. Most of the times 99% of the companies again would probably use docker as a container runtime even though there are like many other alternatives now they're trying to compete with docker but most of you use this. So spend some time understanding what container runtimes are then directly dive into docker maybe a little bit about history of docker and then just move on to you know how can you start containers start create images push images pull images and so on and so forth. There are more advanced concepts here. Docker is one thing I would break into you know three four sub points u which is you know basic docker commands um writing a docker file multi-stage builds orchestrating docker docker has this feature call it a feature but you know an an alternate to kubernetus called docker swarm which you can learn about but no one uses docker swarm almost everyone uses kubernetes in case they want you know a very fancy infrastructure with container orchestration container orchestration is a jargon that I'm using but it basically means orchestrating or starting more than one containers at the same time and uh cubernet is again one way to do it but there are many orchestration uh frameworks and docker has its own docker for swarm cubitus is another one there are many others that let you start instances or more technically containers on thousands of virtual machines why does a company like zeppto not use this why do they use this depends on them I think they have the reasons to and again as a startup things get fairly complicated if you do move to a cubernetes there are a bunch of tweets about people trying to move their infrastructure to ks or kubernetes and they're just moving it back um because of how expensive it is to hire engineers how expensive it is to debug something if any node in your cubernetes cluster goes down. The kind of expertise that is needed to manage a cubernetes cluster is probably something you don't need or any company or most companies don't need. uh which is why it's a great thing to know but most probably if you join a company you might be the one migrating the codebase to cubernetes or the deployments to cubernetes most probably the company that you're hitting if you you know randomly throw an arrow the company is not using cubernetus like a company like razer bit does use cubernetes but you know a company like zeppto does not so it really depends on you know I guess the time that the company has spent I think when razor started they were not on cubernetes I remember when I was just starting out as an engineer they were hiring for this specific role of you know migrating their infra to kubernetes but you get the idea um important concept if you're a devops engineer definitely something you should know I've already broken it down to two parts but probably you know can be broken down into 10 different parts u depending on the depth of kubernetes that you want to go into but if you just want to do the basics I have a video on YouTube and that is probably enough for you to be able to deploy everything uh that you need or you know for stack application or whatever you might need onto a cubernetes cluster all right moving on to a very simple concept CCD yeah if you know how to write tests you should probably be testing every PR on GitHub um if you are deploying an application probably makes sense to deploy directly via GitHub rather than um an engineer actually ssing into a machine, downloading the code, restarting it. U fairly simple concept should probably take you a day. Monitoring and observability is again a fairly vast concept. Um you can spend a lot of time here or null depending on whether or not you want to add monitoring to your application. This is also borderline you know more of a full stack challenge compared to a DevOps challenge. But a lot of times the DevOps team is what is looking at observability tools which is why I've put this here. Um if you join a company and anything breaks engineers are probably sleeping at their houses and they need to be woken up. Um that happens usually in an automated fashion um based on you know if the request latency becomes really high or if the number of failures are really high. All of this needs to be tracked automatically and that broad concept is known as observability. There are many ways and tools to do it. Data dog is a very commonly used public company that probably is worth a lot of money and then there are free alternatives like Grafana, Prometheus. There are many stacks that you can use um to track your application um if it's performing well, if a release has broken something, if the performance is over all going up or overall going down, your net revenue, your net sales or net requests per second, uh f requests, success requests, so on and so forth, which region of the world are people hitting you, what is the time in which your application is alive, all of your logs uh from you know the last 3 months, let's say, all in a single place. So that you know um the engineers can probably just look at those logs in a in a centralized dashboard compared to SSH into various machines are one of many reasons you want monitoring in your application. Any mid-size to big size company will probably have it and again a very niche sort of a skill for someone to know can be broken down into various categories. So you know I've put it as one point here but probably can go fairly deep based on what you're learning. Infrastructure code again something 99% of the companies will not use uh 1% will and depending on a very specific use case sometimes it sort of makes sense to be able to orchestrate nodes or move from one cloud environment to another or just prepare for doomsday or disaster when you have to move you know from one cloud account to another. If that happens, yeah, you know, if you're migrating from one cloud to another or if you're preparing for the day in which your digital ocean account just gets banned, uh, and you need to restart the resources as quickly as possible, it makes sense to have all of your code written in files or all of your infrastructure written in the form of code. That is what I means. Um, it makes it very easy for you to move AC in a multi cloud environment. Um, there are many reasons this happens or many cases in which you need it. I give one example. Um the example is if you a lot of times you need it's a very niche use case a very specific use case but I can still talk about it which is a lot of times you need to build trustless systems by which I mean um your back end is deployed somewhere but you can't really trust the engineer that's you know migrating that or deploying that back end. So you might have three different AWS accounts and have three set of engineers um who are very disjointed. They don't know each other who have access to these three AWS accounts and they can all use the same infrastructure as code files to you know start infrastructure in their respective AWS accounts without being able to talk to each other and without being able to you know clicking buttons in which a developer can make mistake. Um if there is some code that clearly defines what infrastructure needs to start in a specific AWS account, then if you give that code to three different engineers, all three of them um can respectively deploy the same infrastructure in their AWS accounts and by the end uh you have three different you know set of resources that are completely trustless um and not one engineer knows the other engineer. So if an engineer does want to attack your AWS account, the other two AWS accounts will take over. That's one specific use case where IC makes a lot of sense because uh it'll be really hard to track what infrastructure needs to start across three different AWS accounts when the teams can't even talk to each other. But if they have the code all they have to do is apply the code and then the resources would start themselves. That is one specific use case where IC makes sense. Point 8, 9 and 12 are very niche points that most companies would probably not need, would probably not use. Um and that is why it becomes really hard you know even if you have that skill mostly hard to find that company that requires that skill. Even if you do reach that company that does require that skill uh they'll probably you know dismiss you as a very early engineer. Um that's the problem with DevOps generally but as you get more deeper into these topics the problem sort of persists okay people who do have such niche use cases of deploying across the AWS accounts because of to build a trusted system will probably not hire someone who's very early to keeping that in mind it probably makes sense to you know um to figure out when to stop in this DevOps cycle because you can just go very deep and if your motivations are to get a job a lot of times that depth is not going to translate to a job very quickly it probably take years for you to you don't have a lot of experiential learning because before you can actually apply IC to a company or you know change the IC code of a company. All right, CDN's object stores are pretty simple uh should take you less than a day. How should you deploy front ends? How should you or where should you upload images, videos, things like these? Fairly simple concept and should take more than a day. Sandboxing and firecracker is a new one. Firecracker or generally sandboxing is a slightly old concept uh but highly abstracted from us engineers. So whenever you create a virtual machine on AWS or if you've ever dealt with Lambda function on AWS, they run in what's called a sandbox. So if you've created a Cloudflare worker, same thing happens. Your code runs in a sandbox. Um and there's a lot you can do over here to be able to use basically a lot of infrastructure, a lot of machines to deploy 10,000 applications. on you know that hardware that those machines I'm not explaining this really well but basically if you think of lambda functions as or serverless functions as a problem statement how would you let thousands of developers deploy very not very small very much the wrong term but how would you allow thousands of developers all around the world deploy a lambda function or deploy a cloudflare worker a cloudflare worker should scale up and down themselves um or you know a lambda function or a serverless function the scaling of the function depends on um the infrastructure provider which could be AWS or Cloudflare doing that is a little hard because you can't predict traffic to either the AWS or whatever the cloud provider is that's giving you this serverless functionality either they need to scale infrastructure using these constructs ASGS MIGs or Kubernetes um or they can do something else which is called sandboxing which is where firecracker was sort of born firecracker came out of AWS because that was the technology used for virtualization or you know creating small sandboxes in AWS for lambda Eventually it is now being used in various use cases. If you've used lovable look at any AI application even claw today if you see a deployed version of your application it's most probably in a sandbox somewhere and hence you know this use case became very popular in the last 6 months to a year when everyone needed sandboxes to run their AI code. Hence, this is a new sort of something that got saw a lot of growth at the consumer level. But when I say consumer level, I mean developers like you and I had to deal with sandboxes now or this thing called frack firecracker now because developers like you and I now need to deploy AI applications uh for end users. If you're building something like lovable, if you're building something like lovable, you have to deploy AI code for your end users. You probably shouldn't do that, you know, in a non-sandbox environment, which is why everyone is now creating sandboxes and which is why companies like E2B are growing really quickly because E2B is one new company which uses firecracker to basically provide the same functionality lambda did uh but to end users like you and I. So if you're ever building lovable, you'll probably see this in some form of fashion. And not just lovable, this is one example, a lot of other companies even in some concept of context engineering. Um, which is how do you how do you prompt an NLM and try to keep the context really small? Sandboxes are being used to be able to store a lot of the context on sandboxes when you're having a conversation. So whenever you're having a conversation on cloud, most of there's a sandbox somewhere um where a lot of your context is being cached temporarily while you're having the conversation um to keep the final AI context small. So because of these use cases, sandboxing is very popular never really introduced this before but first time I'm you know sharing this as a new thing to learn probably you know if you want to be a devops engineer moving to the projects E2B the technology that I talked about which is a company a B2B company that lets you uh start sandboxes on demand they're open source so if you look at their code base their code is written in go but it's fairly easy to read if you try to you know u reach the right files I've gone through this I'm saying it replet again is a company that would heavily depend on E2B so it would require some level of sandboxing E2B If you use E2P as a blackbox then becomes fairly easy to build. If you don't then again you're basically building the same thing again. So point one and point 2 are fairly similar because a difficult thing in both of them is sandboxing. Um even though in replet there's like a bunch of other challenges because there are 100 different frameworks you have to support or languages you have to support and there at least replet uses concepts like Nyx if you've heard of it uh which you know gives you reproducible builds which basically means if you have if you want to start a NodeJS version with a bunch of dependencies in a predictable fashion then the way to do it is using either docker images or using something like nyx. Um so depends on the depth that you want to build this in. Uh they have a bunch of open source resources sharing uh how reply does it and then cloud workers is probably in the same category. All three of them are very sandbox. I should probably put more projects here. But unfortunately there's not much to build u when it comes to devops. It's more to deploy. So you have a full stack application. How you deploy it? Do you use point number three? Do you use point number eight or nine? Do you use point number five? That depends on you. Um so there's no real project to build other than you know um B2B uh DevOps companies something like E2B or a plate that you know has B2B DevOps challenges. Um resources I don't have many uh unfortunately DevOps again is a very exploratory and experiential field. Keep that in mind if you do want to dive into it. Um the ones that I do I have put up both blogs of two sandboxing companies today. Modal and uh E2B would do the same thing. Um and both have blogs that will probably teach you about this new technology. Everything else a lot of a lot is present on the internet for you to learn. Um so you'll probably have to you know explore those resources yourself. With that we'll move on to the third one which would be let's do AI next. Um what would be a road map for a good AI engineer. Let's get into that next. All right. This road map was built with the help of a friend uh who currently works in an AI company. he's fairly young but um is in the borderline category of a AI researcher and a AI applied AI engineer right now. Um it's a fairly decent road map to understand uh how can you probably get a little bit into research because it does cover some of those topics but mostly around applied machine learning which means I mean basically means building agents um but at the same time um it does answer a bunch of questions in case you do want to get to the history um or understand how LM work under the hood. um kick things off with the history of AI by which I mean um how did we even end up at transformers and how were things done before transformer the architecture came out um a lot of researchers were trying a lot of things and then transformers the specific architecture ended up eating everything else so what were those things um and you know how did we finally arrive at an architecture that's you know probably the best today for not just language tasks but also for you know um image tasks video tasks everything is today being done through transformers um what came before that the answer is you know deep learning and a bunch of math mathematical jargon um which you know are terms like sigmoid functions if you've heard of them or back propagation the standard algorithms that you would use to create neural networks. So if you've ever created neural nets before, if you've done a little bit of deep learning back in college, standard classical machine learning um you know classify if something is a cat or a dog sort of questions or the very standard emnest data set problem of you know identifying a a digit if you've done those that's probably what you need to cover if you haven't done those which is uh how classical machine learning was trying to solve the same problems that transformers are solving today. Then comes a very important concept in the sense um even though it was used in classical machine learning it's also used today um which is neural networks um and PyTorch probably the most popular language you want to code neural networks in you can code a neural network it's just a graph in any language that you want but most probably you want to use a framework like PyTorch to do it because it makes things very easy it's highly optimized most of it you know is boils down to commands in C that you can actually run on you know hardware if you want to and hence makes the developer process life easy and most probably the you squeeze the maximum uh performance from your neural network. If you're using a framework that's highly optimized to do mathematics, matrix, multiplication, whatever rather than writing it yourself, py is fairly vast. It depends on you know again the depth of it. How much of it do you want to learn? Probably makes sense to learn it on the go. As you're building a very basic neural network, learn the very first things and then eventually as you build probably, you know, a transformer yourself um is when you'll learn more functions that PyTorch exposes to you. A few extra classes that I've written over here is again um things that used to happen before attention was a thing that includes recurrent neural networks long short-term memory and sequential models. All of these for in case you wanted to do language tasks which could be completing a sentence like chat does today or translation. And then I've written another one called CNN's which is convolutional neural networks. Again all of this is like pre 2018. I did this back in college like 2015 2016. So none of this is new. None of this is needed either. So it really depends on if you really want to spend your time here. You can directly dive into attention or you can go a little bit into the history and probably spend you know a month understanding how CNN's were trying to target object detection or image or how diffusion was done back then uh for image generation or you can directly dive into attention and you know take everything before that as black boxes but a lot of these things mentioned over here are outdated architectures compared to you know attention and attention doesn't really probably inspires few things from these architectures but uh doesn't really use any of these under the hood. Then comes uh probably which can be the starting point of your learning journey would be coding simple attention and going through the attention paper. The attention paper originally was not built for u you know what we do or use it for today which is having a conversation and you know asking questions getting answers. It was primarily meant for translation. Eventually the architecture was so good that now it's used in not just language tasks but image tasks as well. Um but back then it was created as a translation paper. How can you translate English to Spanish? and attention was a decent architecture to do it. So going through that paper probably just the important parts and trying to code attention um is step one and then diving into a lot of ways it has uh evolved over time. Uh every company has its own architecture of you know coding an LLM today some of them open source some of them not open source but how do you move from that the original attention paper to what chat GBT is today which is you know a user assistant model where you can ask an assistant for to do a bunch of tasks and the assistant will do it for you. This section is primarily on how attention is done today uh by various companies. Um and what are the they're all basically trying to optimize for memory and compute. How quickly can you train a model? How cheaply can you train a model and how cheaply and quickly can you answer a query. So now people are trying to optimize the attention architecture more and more. This includes things like KV cache grouped query attention multi attention and this is a new one that I think deepse released today. I think deep I forgot the full form. Um this came out last week. Point five is around how uh the transformer architecture has evolved over time. Um in the end everyone is trying to optimize for compute uh memory and speed. How can you train a model really fast? How can you train it in a fairly cheaper fashion? Um and how can the model answer queries as quickly as possible? And of course the quality of the final response matters as well. To achieve this attention architecture slowly introduced more and more optimizations. The transformer has gone through a bunch of you know standard optimizations that you might have heard of like KV cache or you know more nuanced and new ones for example I think DSA is the one that came out from deepseek very recently u and everyone sort of you know trying to optimize the attention architecture of the transformer more and more to achieve not just better quality uh but also you know better inference times and consume less memory so on and so forth um so what are the various variations of transformers that you can build how do they apply to the very specific task of you know an assistant answering a user This can go really broad if you want to let's say apply attention to images or other tasks but specifically for NLP tasks. The goal over here should be to build a better and better transformer and use some data set train the model on it and see how the optimizations help in terms of the training time the inference time so on and so forth. Probably up until this point um you should understand what hugging face is uh and what it is used for. It's touted to be you know the alternate of GitHub which is sort of true sort of vague but basically it's a place where people do deploy a bunch of their models data sets and a bunch of other things like they've basically done a lot of things in the same interface. GitHub is very specific for example doesn't let you deploy websites even though it does but like it's not out there on the website on GitHub it's it has a very specific use case versus hugging phase has you know a bunch of tabs um including something like you know hugging space spaces that let you basically deploy websites or applications to you know test on top of an LLM. So it's a more uh jargony sort of an interface but in the end it's a place where you know people are hosting their models, hosting the data sets, hosting spaces to you know showcase to the world basically an open source version of you know a lot of times open source a lot of times just the model the final weights of the model that you can use on your own machine and you know pull the model to your machine and run it from there. So uh understanding how you can interact with the hugging face GUI and how can you use you know a bunch of hugging face libraries to import models to your python code and you know run inference on top of the models that are hosted on hugging face from here most points until point number 13 are more applied AI which again you know more of the field where uh it's easy for an early engineer to get in I think everything we've talked about until this point u is one a lot of history and two a lot of detail around the attention architecture uh which is something can be asked in an interview. I know a guy who just got asked you know um probably not too much but again uh deeper and deeper questions into how attention works and how can you optimize attention. Everything from 7 to3 um is going to cover more application layer things um that a bunch of these LLM providers have provided to us to build on top of them. Um the simplest one you know uh and a very common sort of thing you might have heard of would be vector databases and rack which primarily are used for for search. Um if you have a lot of data that you need to search through to be able to give us context to a prompt which is the most common use case of you know vector databases and drag then comes you know a vector database which basically stores a bunch of text in the form of vectors and if there is some new text that needs to be compared to the the existing text if you want to search on top of the existing text um is where you can use vector databases. It is one of many ways to retrieve text. Um, but there are other ways. For example, you know, for coding tasks, vector databases and drag is not the best way to search for something specific. If you want to search for a specific uh thing in a codebase, vector databases are probably not not the way to go. A simple GP might be, you know, a better way to search through a codebase to find something specific. Um, so it depends on the task. For essays, it probably makes sense because vector databases or, you know, these vectors carry some context and you can search through, you know, let's say Harry Potter novel. um around I don't know Hagrid and it'll give you all the places where Hagrid was mentioned or you know um Hagrid was somewhere in the context um or you know there is some level of Hagrid in that specific statement um compared to uh you know a coding task where uh if you're trying to search for an endpoint where a to-do is being created it's easier for you to grab through the codebase and retrieve it compared to use vector databases. So a very specific thing to learn for specific use cases but not the only way uh to retrieve data. The reason I say that is because it's overused right now I feel um on a bunch of use cases where it doesn't make sense. Um context engineering uh this one is an important long u and a very novel sort of statement. Now context engineering was really a thing like prompt engineering was a thing. Context engineering is something new. Uh it basically means figuring out what's the best context you can send to the LM for a specific task. Um and if there is a lot of back and forth happening between the human and the LLM um how can you keep trimming summarizing breaking the context uh and what are the various approaches to do this um to be able to keep your prompt as you know simple um and most to the point as possible because one you have token limits you can't let's say send more than you know one lakh tokens but two even if you do tend to hit you know 30% of the limits you'll start to see the model hallucinate or you know forget data that's before so it makes sense for you to keep trimming data um what are the various approaches to trim this data? As I said, all of this is very exploratory at the moment and every company is sort of filling this out on the go. Um how can you make an LM really good at longer tasks or you know more difficult tasks? Um context engineering is one way to do it. Um how you do it spec depends on the very specific use case. For a coding task, it would be very different from you know a deep research task. A deep research task goal is to you know research on a very specific topic in the deepest fashion. um a coding task very difficult coding task might be to you know solve a specific bug in a repo. For both of these um it makes sense to do some level of context engineering rather than just you know sending the whole thing to the LM. Um how do you do that? Um how do you summarize how do you uh evaluate if the way that you're doing summarization is is good or bad is you should spend your time on here very exploratory at the moment for you know even companies that are trying to build this. Everyone is you know figuring this out as of today uh as they're you know trying to target their applications to do more difficult tasks. If there's a lovable competitor today that's saying okay we'll build a very elegant uh and end to end full stack application for you that just replaces your business they'll have to spend a lot of time here trying to figure out how can they do such a massive task in a single prompt with that uh agents which is a slightly overused term which it basically means you know talking to an LM and and giving the LM access to some what are technically called tools. So maybe before agents understanding what are tools and then how can you build an agent on top of a tool agent from first principles which basically means you know without any agent framework how can you build an agent and what exactly is an agent and how is it any different from you know a chat interface from which you're talking to an LLM um then probably using an agent framework there are many now crew AI lang chain lang graph figuring out what exactly they're doing um and how they make your life a little easy um when trying to build an agent um specifically if you're trying to you know create multiple agents that need to talk to each other and one agent needs to depend on the response of another agent and one agent needs to be able to call another agent using a library rather than building everything from scratch. Even though building a lot of this from scratch even isn't you know that difficult and a lot of companies today tend to build their agent frameworks in house rather than depending on an agent framework because a lot of these agent frameworks are moving very quickly and you know changing the the way you need to write code using them like langraph is a good example of this. So the original repository was lang chain and then eventually they realized graphs make more sense. So they move on to lang graphs and you know a lot of times there's not enough backward compatibility in these frameworks and hence there's not enough that they provide for you to be able to depend on them. Um but at the same time you should know um how to use one agent framework to you know build an agent memory which is again a very specific concept in terms of the use case. For some use cases long-term memory vector databases make sense. The most common way to do memory is vector databases today. If you have an application that uses AI, let's take a decent example of you know an image repository or let's say text repository a place where you're just dumping text um or dumping blogs and then you you need to be able to search on top of them. Um it would make sense for you to use some sort of memory and most probably vector databases. You can do this using you know an open source vector database that's hosted a propriety vector database that you have to use in a managed fashion. uh or using you know one of many libraries that exist today like if you've heard of M0 or super memory which is trying to tackle the specific problem of memory um and you know uh making it easier for developers to be able to interact with these memory backends or memory databases most of them being you know uh vector databases you can go very deep into this depending on the level of the application for example for cursor they they heavily index your application so it sort of makes sense um for lovable it's a very small application that you're building so most probably context engineering is all that you need um to be able to build something like lovable um to build something like cursor where you need extremely fast responses in terms of the tab response that you need to see um and actually big code bases it makes sense to index the codebase u so you know figuring out when you need it and if you do need it do you use library natively how do you chunk the responses that go into vector database that's probably more of a vector database question than you know a memory question but basically 8 and.12 would probably go you know a lot hand in hand because most common way to do memory right now is using ve vector databases mcp again a fairly new um very close to tool calling. So if you understand tool calls, it's probably very easy. I have a video on it that covers it as well. Uh but long story short, a way for LMS to call not a tool on the back end that invoked the LM um but to call, you know, some sort of a remote tool. Um basically allowing an LLM to be able to interact with, you know, the Zeroda API is the example that I took in my video. But very fancy thing that came out. I don't know how adopted this is at the moment but any chat interface that you go to if you go to claude they do let you you know link your Google drive or your Gmail account through MCPS so that your LLM can interact with your Google drive to help you retrieve images or to your Gmail to you know help you reply on images or summarize an email so on and so forth with that a few other deeper non-applied AI uh topics I wouldn't call these research topics either like they're much simpler compared to uh the attention architectures that we're covering you know from basically 5 and 4 by at the same time slightly more nuanced use cases that only a few companies would need. Computer use is the first one which as the name suggests is how do you allow an LLM to be able to control your machine and the answer pretty much is what you are is in the direction that you're thinking in which is the you take a screenshot you forward it to the LM and the LM tells you where to click and then you click and then you forward another screenshot so on so forth here you can do a bunch of things you can take a screenshot or you can take the HTML of a website and forward it to the LM so the LM can tell you where to click um but to be able to allow the LLM to be able to use your seen um you have to give the LM not just text but you know uh maybe an image maybe a video maybe some HTML like we talked about and this is where you know multimodel agents come into the picture which means a model which can not just take text as an input but also image an image as an input as as easy as that sounds to be able to have an image along with a text we do that on charge fairly often um the math that goes behind it is pretty heavy because you know there's a specific architecture that attention uses to be able to generate more text from text it's a very simple problem it's not a simple problem statement but it's a more defined problem statement I mean compared to an image which is very hard to define as text. Um so how does that happen? How does NLM take not just an image but you know let's say uh not just a text but maybe an image a PDF a video as an input um and is able to gather context on what's happening in the image. Finetuning um what is fine tuning is one topic which is you know understanding what are weights if you understand the attention architecture well you know what are the final set of weights that come and how do you eventually fine-tune your model for specific use cases. Um if you look at any AI lab um they create various variations of their models. There is probably a normal model, there's a smaller model, bigger model, bigger model. There are coding specific models um that come out with you know every release. Um so in the end after the basic model is trained um there is various levels of fine-tuning that happens where the model gets trained on what it eventually needs to do. Does need to solve a user assistant sort of a textual task. Does need to solve a coding task or does need to do I don't know whatever use case you can think of. You might create like a Jsp specific LLM that's just primarily trained on J data. Why would you want to do this? Uh it'll have better responses. You'll be able to serve your customers better. You can also just train an LM that's only trained on J data and nothing else. That way uh your response times are much faster because the LM doesn't really know 100 different things that it doesn't need to know. It only knows enough to be able to answer J questions and nothing else. This is where fine tuning becomes important. One, providing better responses. to creating smaller models like a small language model that is trained on a specific use case um and is not really you know solving things that it doesn't need to really know things that it doesn't need to then fine tuning can be done various ways one is using data and then RL fine which is a more popular concept that specifically became super popular after deepseek through if you've heard of the term RH I think RLF reinforcement learning using human feedback um which basically is you know uh training your model uh by giving it some sort of a reward it answers things well and giving it some sort of a penalization if it doesn't answer things well. Doing this gets very tricky. For example, if you want to train your model to be better at math, then you will ask it a question, it'll give you an answer. And it's very easy for you to tell a math answer is, you know, a simple number. Um, so that's easy to do. Um, giving it some points. If it answers the right things, if it answers the wrong thing, then give it negative points. If it answers somewhere close, then give it slightly positive points. So on and so forth. U this gets tricky on, you know, tasks like coding tasks. How do you train a model that's really good at let's say NodeJS? You'll ask it a NodeJS question, it'll answer a NodeJS answer. How do you evaluate that answer? There are various approaches. You can evaluate using another LM which is one approach or you can create you know specific coding environments in which there is some something that's able to evaluate the response. For example, if if the question that's asked is a competitive examining question, then the response can easily be tested using test cases just like code forces or you know lead code does it. That's one way to create an environment. Uh but this gets more and more tricky based on the specific use cases that you're fine-tuning on. But it's also a better architecture for sure to fine-tune. Um in the end the final response it'll get if you have enough data and enough agents and enough environments to be able to train the model is you know better than if you train the model using data that's already present. So finetuning how do you fine tune using data? How do you fetune using environments and reinforcement learning? Eval's uh writing a bunch of I mean call them tests or you know metrics or benchmarks uh to see if the LM that you've trained is it any better than the LM before um if you start off with you know let's say some version of some any open source model let's say Deepseek um and fine-tune it on a lot of rust data then writing actual tests u which are more technically called evals um that actually tests is it any better is the new model trained on rust code with reinforcement learning any better than the one that's not um so on and so forth so writing a bunch of these is and making sure the final output that you get um you'll be able to quantify it very easily if fine tuning worked or not or you know if one model is better than the other or not and maybe going through some you know open source evals and benchmarks that a lot of these LLM companies optimize for advanced topics there's no end to this put 19 and 20 together um which is all that we've discussed right now is just text which thankfully is most of the you know probably 90% of the use case of LLM right now um but it's not limited LLM isn't limited to just text um voice is the most obvious This next use case, how are voice agents created? Um, not just, you know, you talking to a a chat interface through voice. Um, you know, things like 11 Labs, how is voice actually generated? Music actually generated through AI. Same with video, same with images. There's no end to how much you can learn from here or you know, a specific niche in case you want to dive deeper into it. But all of them boil down onto attention. Now, all of them use some variation of attention um to be able to do you know whatever projects um een framework is the most obvious one and probably the simplest one. um creating something like lang graph uh that lets you create agents, sub agents, lets the agents talk to each other, maybe add some memory on top of it. Why uh it just gives you an idea of what you know u the overused term of an agent means. Um and what does it even mean to you know create an agents framework because in the end um it's just a bunch of LLM calls and a bunch of things people have figured out in the last 2 years. It probably makes sense to you know do LM calls separately. So let's call them two agents and then maybe one LM call depends on another LM call. So let's just call that a sub agent things like these. So a lot of fancy concepts uh but in the end you know very simple constructs if you're trying to build something like this RL fine tuning project writing you as for it this one is really good pick any problem statement let's say a J you know verifier or J fine tuned model or a rust fine model or react fine tune model try to find some data set on it try to train it on the data set and see if it's any better write for it and then think of how can you create an RL training environment um how can you get a data set in which the LM responds and you actually give it points um based on you know if it was a good response or a bad response and how do you actually quantify the response? Can it be done deterministically through tests? If you're doing something like training on you know training on math data or training on Rust or training on competitive programming or can it not be done deterministically for you know tasks like I don't know writing an essay. How do you create an agent or an environment for testing if the response is good for an essay and how is it any different from you know um doing it for competitive programming. Devon which is primarily a DevOps application. I would say it does involve context engineering. Uh but I don't think Devon does any level of indexing the code base or memory yet. I could be wrong. So if you do remove that it's a very simple problem to build and primarily a DevOps challenge of you know when any issue is assigned to Devon where does the sandbox start how does it start? How does the LM talk to the sandbox? How does the sandbox after everything is done and deploy the thing to GitHub. Um lastly, memory frameworks which again mem zero uh was a good example of you know an open source memory framework. It's just an orchestration layer on top of a bunch of memory backends. You can use one of many vector databases to you know store your data. A layer in front of that lets you know choose which back end to use uh or sorry which memory back end to use which vector database to use maybe store things in memory uh so on and so forth. basically would again give you an idea of how memory is an overused or overly glamorized term under the hood it's just vector databases very close to you know the first point here which is that agents is just an overused and overly complicated term which under the hood is just you know a bunch of rm calls cool resources there are many over here most of them are blogs by various companies for example cognition anthropic lang karpathi has or karpati has a YouTube channel which is a little hard to understand I He has a lot of videos, five six hour videos of coding a transformer from scratch and explaining the architecture a bit. Uh a little hard to digest but if you can go through them um then probably the best way to learn attention um you know as quickly as possible. Then there is Corsera which is I mean I primarily used it for classical machine learning back in the day for you know things like deep learning and CNN's. I think it's still free. I could be wrong but I'm unsure if you have they have new they probably do have new courses on attention. I'm not sure if they're paid or not paid. And then lastly, three blue one brown has very simple and nice [snorts] follow along uh videos on the architecture of a transformer. Uh so if you do feel like you're more of a visual learner, then I think this is a great uh channel to go through to just break down the attention paper in a more visual 3D format. Uh and I think he has like six seven videos explaining you know the initial architecture and better attract and optimizations things like these. So if you do feel like you're a visual learner and you do want to learn attention three blue one brown um and Andre Karpathi's channel are more around you know research and understanding transformers everything else is probably going to be you know uh things built on top of LLMs um and you know everything has been figured out in the last one year two year in in you know as people have started to build these agent applications what are the new architectures that they have learned in terms of memory context engineering and you know how it can be applied cool that's AI move on to the fourth section next which Web three pretty big shift honestly just pick one if you do if you do think of you know picking of one of two fascinating fields A and web 3 just pick one uh because both of them require a lot of uh great time and energy to go through uh the last one web 3 it's road map projects and resources 3 starts off with intro to blockchains that's primarily you know why were they introduced uh what exactly is a blockchain what purpose does it solve basically going through a bunch of videos very honestly rather than um text uh trying to understand uh Bisantine fault tolerance or you know distributed systems a bit or just understanding why can't you do bitcoin without miners uh why does everyone all around the world need to start these miners and validators to run a blockchain uh rather than you know it just being a single machine like HTFC bank has it then moving on to some cryptography which is what makes.1 possible uh because mostly you Blockchains are cryptography not in terms of you know the private keys that we hold but also a bunch of communications that happen um amongst the validators and you know specifically in case of bitcoin the validation the way it is done um is done through a bunch of cryptography so primarily up until I would still spend my time on bitcoin understanding why it was introduced because everything else is just a variation on top of bitcoin um and everything else is solving the same use case which is uh creating a decentralized currency uh that was that's what bitcoin did Um the other blockchains do 10 different things on top. But if you understand Bitcoin then slightly becomes easy to understand these more complicated architectures. Think of it like the initial attention architecture and then optimizations on top of it or variations on top of it. So Bitcoin initial architecture and then Ethereum Solana other blockchain you can think of more variations on top of the same based problem of decentralized money or decentralized code execution. Understanding the architecture of Solana is probably a lot of videos if you want to go through the white paper and you know understand them in depth. How does a validator run and what all processes are running inside a validator and how do the validators communicate with each other? How is consensus reached? U or you can learn it from slightly high level understanding what are blocks, what are slots, how are transactions packed together, how does how is the leader decided, how is it decided? What validator validates a specific transaction? Um so on and so forth. Um so you should decide how interesting it is and how you're losing interest on point number three. And if you feel like you're losing interest very quickly by going through the white paper, skip the white paper for now. You can always come back to it. The Bitcoin white paper you should definitely read. This is not a white paper. depend on if you're able to digest it or not. Then comes jargon. I've mentioned two of these authority and owner but there are like probably 30 different jargon to go through. Program accounts uh you know system account uh system program authority owner are two uh probably there many more that I can't think of right now but I can go through the docs and quickly find what else is a good jargon. PDS is another good jargon. uh but I've just mentioned that as a specific you know a different point because it's really hard to digest what program derived addresses are why are they needed and it takes a few iterations to understand it um think of them as you know two set of things you need to learn a bunch of jargon joints um what is authority what is an owner but eventually it'll make sense when you reach you know smart contracts and executions and start writing smart contracts but spend some time here so that um eventually you don't get overwhelmed when you're writing contracts writing front ends doing things like these a bunch of jargon PDAs Um and then probably the simplest part of this whole architecture which is going to be going through client side uh Solana libraries Solana/WP.js is the OG one. Now there are new libraries that are coming that are trying to replace it. Uh but basically is a library that lets you interact with the Solana blockchain. So if you want to at a very high level just interact with the Solana blockchain and you know check how much Solana does hold then you can use this library call a simple function get balance pass in my public key and you'll get the balance of Sana that I hold or the balance of USDC that I hold so on and so forth. So another library I would like to add over here would be add Sana/ SPL token which lets you get someone's token balance. What is a token? um USDC, USDT, Trump, uh Bonk, Beam coins, a bunch of these are tokens on the Solana blockchain. Um so if you do want to get my Solana balance, you'll get it using at Solana/W3.js. If you do want to get my USDC balance, then you'll have to use a different library called at Solana/SPL token. You don't need these libraries. They just make provide you extremely high level functions to be able to gather information like this. You can gather this information without using these libraries as well. Um if you do not use these libraries though you have to basically decode a lot of bytes um into numbers um into textual data um which gets really hard and they abstract all of this from you which is why people tend to use these libraries rather than interacting with the blockchain themselves. The data model on Sana it's very clo if you understand PDS you'll understand the data model. Uh but basically Slana is very different from how Ethereum is. If you're learning Ethereum um your life would be much simpler because the language that is used to write smart contracts there solidity because of how data is stored on the Ethereum blockchain. On Solana things are a little tricky and kudos to the founders you know initial people who've think thought of this architecture because it's pretty elegant in terms of what the data model on Sana is at the same time it's very confusing. It takes you know few iterations to be able to understand it. Once you get it, there is a light bulb movement and you'll you totally understand why it was made up the way it was made. But the data model and PDS go hand in hand. So 0.5 and point8 uh make sure you do understand them before you move on to the token program. There's no way you're understanding the token program if you don't understand what PDS are. The token program is the very first smart contract that you should look at. Um after you're able to interact with the blockchain, after you're able to send some money, you're able to create a wallet application. Basically, if you can create a wallet of your own is when you need to now start to dive deeper into u more complicated programs. Um token program is one such program and it's very vast in terms of you know what it does, how it does it um and the kind of jargon you need. Basically, yeah, a lot of filteration happen at this happens at this point because a lot of people are not able to digest how the token program is written um and what it does. So keep that in mind if when you reach this point um and only if you are comfortable with the token program is when you should move to the next section which is D5 or decentralized finance or how can you swap one token for another which is the simple simplest you know problem statement to solve over here. There are various call them architectures call them u you know approaches to allow people to swap money in a decentralized fashion. Um the most oldest one is AMMs or automated market makers and then the list is never ending. people now have you know now we have something called prop amm which is the most recent optimal way to swap one token for another um but the more OG ones and more ones that are available you'll find source code for them somewhere um are you know amms and I wouldn't put puts in this category u honestly I would put amms and cms in one category and perhaps a very separate topic because it's very different from what the first three do the first three let you swap one token for another the fourth one just lets you speculate on the price of a token so it's a little different from the first three u probably breaks this down to two points probably don't learn about pops until a long time um especially if you're trying to code them a little hard to code compared to the first three rust easy rust advance that's something that's good to know generally um I think if you want to be a distributed system engineer or you know uh want to join a company where rust is being used you will have to spend your time learning not just the syntax but 10 different things that happen in rust I have two videos that you can go through if you want to understand them there's another very good resource called the rust book that you can go through but it's not easy to write Rust because of just how the language is written. Um, the reason it's written that way is to provide a bunch of safety guarantees to you when it comes to memory. Um, right, my camera died, so I'm just going to move to my webcam for the rest of the video. We were here on Rust. After you're done with the Rust, you should probably learn about Anchor. It's a framework in Solana that lets you build smart contracts easily. Probably one thing you should do before this is write native contracts. After you've written native contracts in Solana um which were the original way to write contracts in rust you can learn about this framework called anchor that makes your life a little bit easy um then you can probably write start to write some basic what might be as in interview kind of contracts um staking and escro are the more popular ones um you can write them in Rosana you can write them natively you can write them using anchor you can write them in a third framework called Pinocchio um probably do all three um and one thing I would probably uh urge at this point is to create uh clients and tests for this which is written here eventually. Um a client basically means writing some highle functions in JavaScript, TypeScript, Python um to call that specific smart contract function. Tests as the name suggests writing tests for it which could be directly in Rust or in Typescript. Um then comes indexing which is a sort of an underrated topic. Uh by which I mean it's something that most companies need. A lot of companies would depend on third parties to be able to index the Solana blockchain. What indexing means is reading every transaction maybe that's happening on the Solana blockchain or you know specific transactions that solve something specific. For example, uh you might want to index all the swaps that are happening on a specific DEX or you might want to swap uh index every new token that has been created on the Tana blockchain. Things like these. How do you do it in house? How do you do it? by depending on someone else MPCs and shamirs which are more private key specific concepts uh in case you do feel like uh holding your end users private keys how can you do it how can you do it in a more uh secure fashion um and how can you try to get rid of you know as many vulnerabilities as possible in case you do want to hold your end users private keys generally not the great idea but for some specific use cases it makes sense um a good use case might be you know something like Privy u which basically lets end users or other platforms u onboard users using their Google account um or their phone number. Um so if you do want to allow your end users to you know not understand or know the concept of private keys um but just want to let them login via Google um is where you need to understand what MPCs are or what shame secrets are and how can you hold the end user's private key for them. Ad hoc web 2 plus web 3 and partially centralized contracts are pretty close-knit. By which I mean a lot of times a lot of applications that you interact with on the blockchain are not completely decentralized. I think the recent Camino versus Jupiter feud had some points around Jupiter's lending protocol not being completely decentralized. Um and a lot of times it sort of makes sense um for a few applications not to be completely decentralized but to be partially centralized. Why? mostly on the answer is speed or you know compute limits or storage limits on Solana. Um so it one it's not possible to do it two it just makes it faster to be offchain. Um and hence there's a combination of a centralized and a decentralized contract that you might have to create. So how do you create those? Um and what specific use cases do you need them for and how how does the centralized back end in that case talk to the blockchain and you know if your end user does interact with your contract how does the centralized layer actually know about it and execute the final thing that needs to be executed. Cool. The projects are I've written many DEX and SEX are the popular ones. So centralized exchange is probably been the same for many years now. I think the New York Stock Exchange whatever architecture they have um just use the same that's probably what every centralized exchange is using right now. DEX architectures keep on changing over time. Um AMM is the oldest one. Then there was CMM. Um you can go to DMM. I think that's pretty good right now even though now there are not newer architectures but at least newer competitors in this niche. if you've heard of prop ammms um how do they work I think is a very u unknown challenge at the moment um and what is there a specific architecture they're using or something else um to be able to trade so efficiently on chain is something we'll probably know in the next 6 months but right now DMM is the probably you know the gold standard of a dex that you can create right now a wallet is a more simpler application probably something to do at this point so that you know um you're okay or you know decent at client side um prediction market is a new thing to introduce because of prediction market um they just became popular right now Kashi and uh poly market made them super popular and they're much simpler to code compared to a dex and they're competing with dexes in terms of you know daily volumes um which is why uh I think a prediction market at least right now is a decent project to build um it also give you a decent idea of how you can build on chain autobooks which is something that's that was done on dexes but never really took off um but probably something that will take off u you know works well in production um for prediction markets. Lastly, front ends. I've already talked about this, but whatever contacts you're writing, which there are some simple ones over here, more complicated ones over here. Writing clients for them, tests for them or front ends for them. A few resources. This is a very comprehensive resource. Um, it's very vast. It also covers a lot of topics that you may or may not need. U hence steer with caution. But it's a great resource if you want to learn blockchains very comprehensively and let's say you have one and a half years, then a great curriculum to go through. Um the Bitcoin white paper is something everyone should go through once in their life. Um and if you do want to learn Rust, this is where I tend to learn it from which is another YouTuber called John, but it's his videos are a little too technical. So just you know pick and choose if you want to go to this channel or something else specifically for us, nothing related to Solana over here. That covers web 3, which pretty much means it covers everything we had to cover in this video. This video was a road map on four niches. Hopefully you have some insights on what is needed to build in these four niches. I would still say start with full stack if you're very early. If you are already a decent size engineer, you have a job, you've been working in the industry for a year or two, or if you're really smart and early, then feel free to pick AI web 3, whatever you want. And lastly, this syllabus was a a small tease of what you know we've been trying to build up for the next cohort atex school. Um, so if you do feel like you want to join this and learn all of this with a community for a fairly cheap price, I think it'll be like 4 5,000 rupees this time. Then feel free to join the cohort whenever it comes. If if it does come, it'll probably come in the next 10 days or so. If that does happen, I'll see you in the cohort. If not, there are resources, free resources, topics, everything out there. So do spend your time u and you know, learn these resources yourself. And hopefully it was a insightful road map for all four of these for you. With that, we'll end it. I'll see you where the next one.",
  "notes": {
    "summary": "This lecture provides a roadmap for learning computer science skills in four high-demand niches: Fullstack, DevOps, AI, and Web3. It outlines specific learning paths, project suggestions, and resources for each niche, emphasizing practical application and job market readiness. The speaker advises beginners to start with Fullstack development and suggests that while DevOps is critical, entry-level roles are scarce, often requiring prior experience in other engineering roles. AI and Web3 are presented as more specialized fields with distinct learning curves and applications.",
    "key_concepts": [
      "Fullstack Development",
      "DevOps",
      "Artificial Intelligence (AI)",
      "Web3",
      "MERN Stack",
      "Containerization (Docker)",
      "Large Language Models (LLMs)",
      "Blockchain",
      "Smart Contracts",
      "Attention Architecture"
    ],
    "topics": [
      {
        "name": "Fullstack Development Roadmap",
        "description": "A detailed curriculum for becoming a fullstack developer, covering frontend, backend, and database technologies.",
        "keywords": [
          "HTML",
          "CSS",
          "JavaScript",
          "Node.js",
          "Express",
          "MongoDB",
          "React",
          "TypeScript"
        ]
      },
      {
        "name": "DevOps Learning Path",
        "description": "An overview of essential DevOps concepts and tools for managing infrastructure, deployment, and operations.",
        "keywords": [
          "Terminal",
          "VMs",
          "Cloud",
          "Docker",
          "Kubernetes",
          "CI/CD",
          "Observability",
          "IaC"
        ]
      },
      {
        "name": "AI Engineering Curriculum",
        "description": "A roadmap for aspiring AI engineers, focusing on the history, core concepts, and practical applications of AI, particularly LLMs.",
        "keywords": [
          "Deep Learning",
          "Neural Networks",
          "PyTorch",
          "Transformers",
          "LLMs",
          "Vector Databases",
          "Agents",
          "Fine-tuning"
        ]
      },
      {
        "name": "Web3 Development Guide",
        "description": "A structured approach to learning Web3 technologies, including blockchains, cryptography, smart contracts, and decentralized applications.",
        "keywords": [
          "Blockchain",
          "Cryptography",
          "Solana",
          "Smart Contracts",
          "DEX",
          "DeFi",
          "Rust",
          "Anchor"
        ]
      },
      {
        "name": "Project-Based Learning",
        "description": "Emphasis on building practical projects to solidify understanding and demonstrate skills in each niche.",
        "keywords": [
          "To-do App",
          "E-commerce",
          "AI Agents",
          "DEX",
          "Wallet",
          "Projects"
        ]
      },
      {
        "name": "Resource Recommendations",
        "description": "Suggestions for learning resources, including online courses, documentation, blogs, and open-source projects.",
        "keywords": [
          "Udemy",
          "YouTube",
          "GitHub",
          "Blogs",
          "Documentation",
          "Open Source"
        ]
      }
    ],
    "detailed_notes": "## Lecture Overview\n\nThis lecture provides a roadmap for learning computer science skills in four high-demand niches: Fullstack, DevOps, AI, and Web3. The goal is to equip learners with skills that allow for entry-level job opportunities and immediate value contribution to companies. The speaker emphasizes practical project building and suggests a learning timeline of 6-8 months to become proficient in one niche.\n\n## Key Niches and Entry Points\n\n*   **Fullstack:** Recommended for complete beginners due to its relative simplicity and commoditization. Can be learned in approximately 2 months with decent CSIQ.\n*   **DevOps:** Considered harder to get hired for as an entry-level role. Growth often comes from transitioning from other engineering roles. Requires some financial investment for cloud environments ($100).\n*   **AI:** Focuses on applied machine learning and building agents, with an understanding of LLMs and their underlying architecture.\n*   **Web3:** Involves learning about blockchains, cryptography, smart contracts, and decentralized applications.\n\n## Fullstack Development Roadmap\n\n### Core Technologies\n\n*   **Frontend Basics:**\n    *   HTML, CSS: Spend about a week on basics.\n    *   JavaScript:\n        *   Basics (syntax)\n        *   Architecture of JS & Async.js (can be challenging for beginners, consider revisiting)\n        *   Client-side vs. Server-side JavaScript\n*   **Backend Development:**\n    *   HTTP Protocol: Fundamental for web applications.\n    *   Express.js: A popular Node.js framework for building HTTP servers. Significant time investment recommended.\n    *   Databases:\n        *   MongoDB: Simple to learn for beginners.\n        *   PostgreSQL/MySQL: Essential for production environments. Learn SQL queries.\n        *   ORMs (Object-Relational Mappers) like Prisma.\n*   **Modern Enhancements:**\n    *   TypeScript: Understand its differences from JavaScript and Node.js.\n    *   Bun.js: A faster JavaScript runtime.\n    *   Turbo Repo: For monorepos and build systems.\n*   **Frontend Frameworks:**\n    *   React: Core frontend library. Requires 5-6 days of effort.\n    *   Tailwind CSS: For styling.\n    *   Next.js: A popular framework, sometimes used for both frontend and backend.\n*   **Advanced Concepts (Optional for entry-level):**\n    *   WebSockets, WebRTC.\n    *   Queues and Pub/Sub for backend communication.\n\n### Projects\n\n*   **Initial Projects:** To-do app, a simple e-commerce app.\n*   **Advanced Projects:**\n    *   Lovable (AI application)\n    *   Quote vs. Trading App (may require WebSockets or queues)\n\n### Resources\n\n*   Channel's own content (covers many fullstack topics).\n*   Udemy courses (e.g., Agile's cheap courses).\n*   React documentation (excellent, but can be challenging for beginners).\n*   Open-source projects (GSOC organizations, open-source companies).\n\n## DevOps Learning Path\n\n### Core Concepts\n\n*   **Terminal Proficiency:** Basic bash commands, Vim/Neovim (optional).\n*   **Virtual Machines (VMs) & Bare Metal:** Understanding deployment environments.\n*   **Process Management & Reverse Proxies:** Ensuring application uptime and deploying multiple services on one server.\n*   **Certificates & HTTPS:** Securing web traffic.\n*   **Scaling Infrastructure:**\n    *   Auto-scaling groups (AWS), Managed Instance Groups (GCP).\n*   **Containers:**\n    *   Container Runtimes (Linux-specific).\n    *   Docker: Images, containers, Dockerfiles.\n    *   Container Orchestration: Kubernetes (complex, often not needed for smaller companies).\n*   **CI/CD (Continuous Integration/Continuous Deployment):** Automating testing and deployment.\n*   **Monitoring & Observability:** Tools like Grafana, Prometheus, DataDog for tracking application health.\n*   **Infrastructure as Code (IaC):** Terraform, CloudFormation (niche, but useful for multi-cloud or disaster recovery).\n*   **Sandboxing & Firecracker:** For running untrusted code, crucial for serverless functions and AI applications.\n*   **CDNs & Object Stores:** For deploying frontends and storing assets.\n\n### Projects\n\n*   Deploying a fullstack application using various DevOps tools.\n*   Building B2B DevOps companies like E2B (sandboxing) or Replit (complex environments).\n*   Cloudflare Workers (serverless).\n\n### Resources\n\n*   Blogs of sandboxing companies (Modal, E2B).\n*   Extensive online resources.\n\n## AI Engineering Curriculum\n\n### Foundations\n\n*   **History of AI:** From classical ML to Transformers.\n*   **Deep Learning & Math:** Sigmoid functions, backpropagation.\n*   **Classical Machine Learning:** Classifiers (cat/dog), MNIST.\n*   **Neural Networks:**\n    *   PyTorch: Primary framework for building neural networks.\n    *   RNNs, LSTMs, Sequential Models (pre-attention era).\n    *   CNNs (Convolutional Neural Networks).\n\n### Transformers and LLMs\n\n*   **Attention Mechanism:** Understanding the original attention paper and its evolution.\n*   **Transformer Architectures:** Optimizations for memory and compute (KV cache, grouped query attention, DSA).\n*   **Hugging Face:** Platform for models, datasets, and demos.\n\n### Applied AI\n\n*   **Vector Databases & RAG (Retrieval Augmented Generation):** For search and context retrieval.\n*   **Context Engineering:** Optimizing prompts and managing token limits.\n*   **Agents:** LLMs with access to tools, using frameworks like LangChain, CrewAI.\n*   **Memory:** Long-term memory using vector databases.\n*   **Tool Calling (MCPs):** LLMs interacting with external APIs.\n\n### Advanced/Niche Topics\n\n*   **Computer Vision:** Multimodal agents (text, image, video input).\n*   **Fine-tuning:** Adapting models for specific tasks (data-driven, RLHF).\n*   **Evaluation (Evals):** Benchmarking and testing LLM performance.\n*   **Non-Text Modalities:** Voice, music, video generation.\n\n### Projects\n\n*   Building an agent framework.\n*   RL fine-tuning project with evals.\n*   Devon (DevOps application involving context engineering).\n*   Memory frameworks (e.g., MemZero).\n\n### Resources\n\n*   Blogs from AI companies (Cognition, Anthropic).\n*   Andrej Karpathy's YouTube channel (coding transformers from scratch).\n*   Coursera (classical ML, deep learning).\n*   Three Blue One Brown (visual explanations of transformer architecture).\n\n## Web3 Development Guide\n\n### Blockchain Fundamentals\n\n*   **Introduction to Blockchains:** Purpose, Byzantine Fault Tolerance, distributed systems.\n*   **Cryptography:** Key to blockchain security and communication.\n*   **Bitcoin:** Understanding its architecture and purpose as the foundation.\n*   **Other Blockchains:** Ethereum, Solana (variations on decentralized money/code execution).\n\n### Solana Specifics\n\n*   **Validator Architecture:** How validators run and communicate.\n*   **Jargon:** Program Derived Addresses (PDAs), authority, owner.\n*   **Client-Side Libraries:** Solana/Web3.js, Solana/SPL Token.\n*   **Data Model:** Understanding Solana's unique data model and its relation to PDAs.\n*   **Token Program:** First smart contract to learn.\n*   **DeFi (Decentralized Finance):**\n    *   Automated Market Makers (AMMs).\n    *   Concentrated Liquidity Market Makers (CMMs).\n    *   Pro AMMs (newer, more efficient).\n    *   Derivatives (e.g., Futures, Options).\n*   **Rust Programming:** Essential for Solana smart contracts. Anchor framework for easier development.\n*   **Smart Contracts:** Staking, Escrow. Writing clients and tests.\n*   **Indexing:** Reading and processing blockchain transactions.\n*   **MPC & Shamir's Secret Sharing:** Secure private key management.\n*   **Hybrid Architectures:** Partially centralized contracts for speed/efficiency.\n\n### Projects\n\n*   Decentralized Exchanges (DEXs) and Centralized Exchanges (CEXs).\n*   Wallets.\n*   Prediction Markets.\n*   Writing clients, tests, and frontends for smart contracts.\n\n### Resources\n\n*   Comprehensive blockchain curriculum (use with caution).\n*   Bitcoin white paper.\n*   Rust programming resources (John, The Rust Book).\n\n## General Advice\n\n*   **Start with Fullstack:** If you are a complete beginner.\n*   **Choose One Niche:** AI and Web3 are specialized and require significant time.\n*   **Project-Based Learning:** Crucial for demonstrating skills.\n*   **Community Learning:** Cohorts can provide structured learning and support.\n*   **Continuous Learning:** The tech landscape evolves rapidly, so ongoing learning is essential."
  },
  "questions": [
    {
      "question": "The lecture mentions 'Attention Architecture' as a key concept. In which of the four high-demand niches is this concept most likely to be relevant?",
      "options": [
        "Fullstack Development",
        "DevOps",
        "Web3",
        "AI"
      ],
      "correct_answer": 3,
      "explanation": "Attention Architecture is a fundamental concept in modern Artificial Intelligence, particularly in the development of transformer models used in LLMs.",
      "topic": "Artificial Intelligence (AI)",
      "difficulty": "hard"
    },
    {
      "question": "What is the function of a JavaScript runtime like Bun.js, as mentioned in the 'Modern Enhancements' for Fullstack development?",
      "options": [
        "To serve as a database",
        "To provide a faster alternative to Node.js",
        "To manage cloud infrastructure",
        "To write smart contracts"
      ],
      "correct_answer": 1,
      "explanation": "Bun.js is presented as a 'faster JavaScript runtime,' suggesting its role in executing JavaScript code more efficiently.",
      "topic": "Fullstack Development",
      "difficulty": "hard"
    },
    {
      "question": "What is a concept mentioned in the lecture that is crucial for AI engineers to understand, related to the architecture of AI models?",
      "options": [
        "Attention Architecture",
        "MERN Stack",
        "Containerization",
        "SQL Queries"
      ],
      "correct_answer": 0,
      "explanation": "The lecture specifically mentions 'Attention Architecture' as a concept within AI development, particularly relevant to LLMs.",
      "topic": "Artificial Intelligence (AI)",
      "difficulty": "easy"
    },
    {
      "question": "According to the lecture summary, what is the recommended starting point for complete beginners in computer science skills?",
      "options": [
        "DevOps",
        "AI Engineering",
        "Fullstack Development",
        "Web3 Development"
      ],
      "correct_answer": 2,
      "explanation": "The lecture explicitly recommends Fullstack Development as the starting point for complete beginners due to its relative simplicity and commoditization.",
      "topic": "Fullstack Development",
      "difficulty": "medium"
    },
    {
      "question": "What is the term for managing infrastructure, deployment, and operations in the context of DevOps?",
      "options": [
        "Frontend Development",
        "Containerization",
        "AI Engineering",
        "Blockchain"
      ],
      "correct_answer": 1,
      "explanation": "Containerization (like Docker) is a key tool and concept within the DevOps learning path for managing infrastructure and deployment.",
      "topic": "DevOps",
      "difficulty": "easy"
    },
    {
      "question": "What is the fundamental protocol for web applications that backend developers need to understand?",
      "options": [
        "TCP/IP",
        "HTTP Protocol",
        "FTP",
        "SMTP"
      ],
      "correct_answer": 1,
      "explanation": "Understanding the HTTP Protocol is fundamental for backend development in web applications.",
      "topic": "Fullstack Development",
      "difficulty": "easy"
    },
    {
      "question": "What is the fundamental protocol for web applications that is listed as essential for backend development in the Fullstack roadmap?",
      "options": [
        "TCP/IP",
        "FTP",
        "HTTP",
        "SSH"
      ],
      "correct_answer": 2,
      "explanation": "The Fullstack Development Roadmap explicitly states that the 'HTTP Protocol' is 'Fundamental for web applications.'",
      "topic": "Fullstack Development",
      "difficulty": "hard"
    },
    {
      "question": "For Fullstack development, approximately how much time is recommended to spend on the basics of HTML and CSS?",
      "options": [
        "1-2 days",
        "About a week",
        "1 month",
        "2 months"
      ],
      "correct_answer": 1,
      "explanation": "The lecture suggests spending about a week on the basics of HTML and CSS for Fullstack development.",
      "topic": "Fullstack Development",
      "difficulty": "easy"
    },
    {
      "question": "Which database technology is suggested as a simpler option for beginners in the Fullstack development roadmap?",
      "options": [
        "PostgreSQL",
        "MySQL",
        "MongoDB",
        "SQL"
      ],
      "correct_answer": 2,
      "explanation": "The Fullstack Development Roadmap section on databases states that 'MongoDB: Simple to learn for beginners.'",
      "topic": "Fullstack Development",
      "difficulty": "hard"
    },
    {
      "question": "Which database technology is essential for production environments in Fullstack development, requiring knowledge of SQL queries?",
      "options": [
        "MongoDB",
        "Redis",
        "PostgreSQL/MySQL",
        "Cassandra"
      ],
      "correct_answer": 2,
      "explanation": "PostgreSQL and MySQL are essential for production environments and require learning SQL queries.",
      "topic": "Fullstack Development",
      "difficulty": "easy"
    },
    {
      "question": "Which of the following is NOT listed as a core technology within the Fullstack Development Roadmap?",
      "options": [
        "HTML",
        "CSS",
        "JavaScript",
        "Python"
      ],
      "correct_answer": 3,
      "explanation": "The Fullstack Development Roadmap details frontend basics (HTML, CSS, JavaScript), backend development (Express.js, HTTP, Databases), and modern enhancements (TypeScript, Bun.js, Turbo Repo). Python is not mentioned as a core technology for this roadmap.",
      "topic": "Fullstack Development",
      "difficulty": "hard"
    },
    {
      "question": "What is the primary goal of learning computer science skills as outlined in the lecture?",
      "options": [
        "To become a theoretical researcher",
        "To gain skills for entry-level job opportunities and immediate value contribution",
        "To master every aspect of computer science",
        "To focus solely on academic learning"
      ],
      "correct_answer": 1,
      "explanation": "The lecture states its goal is to equip learners with skills that allow for entry-level job opportunities and immediate value contribution to companies.",
      "topic": "Lecture Overview",
      "difficulty": "medium"
    },
    {
      "question": "Which database technology is recommended for beginners in the Fullstack roadmap due to its simplicity?",
      "options": [
        "PostgreSQL",
        "MySQL",
        "MongoDB",
        "Prisma"
      ],
      "correct_answer": 2,
      "explanation": "The lecture notes specifically mention MongoDB as being simple to learn for beginners in the database section of the Fullstack roadmap.",
      "topic": "Fullstack Development",
      "difficulty": "medium"
    },
    {
      "question": "According to the lecture, what is the main objective of learning the skills outlined in the roadmaps?",
      "options": [
        "To become a theoretical computer scientist",
        "To gain skills for immediate value contribution and entry-level job opportunities",
        "To exclusively focus on academic research",
        "To develop niche expertise without job market relevance"
      ],
      "correct_answer": 1,
      "explanation": "The lecture overview states the goal is to 'equip learners with skills that allow for entry-level job opportunities and immediate value contribution to companies.'",
      "topic": "Lecture Overview",
      "difficulty": "hard"
    },
    {
      "question": "What is a key characteristic of Fullstack development that makes it recommended for beginners?",
      "options": [
        "High specialization",
        "Relative simplicity and commoditization",
        "Requires significant financial investment",
        "Focus on niche areas like AI"
      ],
      "correct_answer": 1,
      "explanation": "Fullstack development is recommended for beginners due to its relative simplicity and its commoditized nature in the job market.",
      "topic": "Fullstack Development",
      "difficulty": "easy"
    },
    {
      "question": "According to the lecture, which of the four high-demand niches is recommended as the starting point for complete beginners in computer science?",
      "options": [
        "DevOps",
        "AI",
        "Fullstack",
        "Web3"
      ],
      "correct_answer": 2,
      "explanation": "The lecture explicitly recommends Fullstack development for complete beginners due to its relative simplicity and commoditization, making it an accessible entry point.",
      "topic": "Fullstack Development",
      "difficulty": "hard"
    },
    {
      "question": "In the Web3 development guide, what foundational element is mentioned as being crucial to learn alongside cryptography and smart contracts?",
      "options": [
        "Express.js",
        "Client-side JavaScript",
        "Blockchains",
        "MERN Stack"
      ],
      "correct_answer": 2,
      "explanation": "The Web3 Development Guide outlines learning about blockchains, cryptography, smart contracts, and decentralized applications, with blockchains being a fundamental component.",
      "topic": "Web3",
      "difficulty": "hard"
    },
    {
      "question": "The lecture suggests that while DevOps is critical, entry-level roles are scarce. What is a common pathway for individuals to move into DevOps roles?",
      "options": [
        "Completing a Web3 certification",
        "Transitioning from other engineering roles",
        "Focusing solely on AI research",
        "Building complex Fullstack applications"
      ],
      "correct_answer": 1,
      "explanation": "The lecture states that 'Growth often comes from transitioning from other engineering roles,' indicating this is a common path into DevOps.",
      "topic": "DevOps",
      "difficulty": "hard"
    },
    {
      "question": "What is the estimated learning timeline suggested by the speaker to become proficient in one of the discussed niches?",
      "options": [
        "1-2 months",
        "3-4 months",
        "6-8 months",
        "Over a year"
      ],
      "correct_answer": 2,
      "explanation": "The lecture overview states that the 'goal is to equip learners with skills that allow for entry-level job opportunities and immediate value contribution to companies. The speaker emphasizes practical project building and suggests a learning timeline of 6-8 months to become proficient in one niche.'",
      "topic": "Lecture Overview",
      "difficulty": "hard"
    },
    {
      "question": "The lecture categorizes AI and Web3 as which type of fields compared to Fullstack Development?",
      "options": [
        "More General",
        "Less Technical",
        "More Specialized",
        "Easier to Enter"
      ],
      "correct_answer": 2,
      "explanation": "AI and Web3 are presented as more specialized fields with distinct learning curves and applications, differentiating them from the recommended entry point of Fullstack.",
      "topic": "Lecture Overview",
      "difficulty": "medium"
    },
    {
      "question": "What is a key concept in AI development mentioned in the lecture, particularly related to understanding underlying architectures?",
      "options": [
        "MERN Stack",
        "Containerization",
        "Large Language Models (LLMs)",
        "Blockchain"
      ],
      "correct_answer": 2,
      "explanation": "The lecture highlights Large Language Models (LLMs) and their underlying architecture as a focus within AI development.",
      "topic": "Artificial Intelligence (AI)",
      "difficulty": "easy"
    },
    {
      "question": "Which Node.js framework is recommended for building HTTP servers in the Fullstack development roadmap?",
      "options": [
        "Prisma",
        "Bun.js",
        "Express.js",
        "Turbo Repo"
      ],
      "correct_answer": 2,
      "explanation": "The Fullstack Development Roadmap explicitly mentions Express.js as a popular Node.js framework for building HTTP servers.",
      "topic": "Fullstack Development",
      "difficulty": "hard"
    },
    {
      "question": "What is a key component of Web3 development that involves writing code to automate agreements and transactions on a blockchain?",
      "options": [
        "Containerization",
        "Attention Architecture",
        "Smart Contracts",
        "Frontend Basics"
      ],
      "correct_answer": 2,
      "explanation": "The Web3 Development Guide section mentions Smart Contracts as a key technology, which are used to automate agreements and transactions on a blockchain.",
      "topic": "Web3",
      "difficulty": "medium"
    },
    {
      "question": "Which of the following niches is described as having scarce entry-level roles, often requiring prior experience in other engineering fields?",
      "options": [
        "Fullstack Development",
        "AI Engineering",
        "Web3 Development",
        "DevOps"
      ],
      "correct_answer": 3,
      "explanation": "The lecture notes state that entry-level roles in DevOps are scarce and that growth often comes from transitioning from other engineering roles.",
      "topic": "DevOps",
      "difficulty": "medium"
    },
    {
      "question": "What is the primary reason cited in the lecture for DevOps roles being difficult to secure at an entry-level?",
      "options": [
        "High cost of learning resources",
        "Lack of online courses",
        "Requirement for prior engineering experience",
        "Limited demand in the job market"
      ],
      "correct_answer": 2,
      "explanation": "The lecture states that growth in DevOps often comes from transitioning from other engineering roles, implying that entry-level positions are scarce and typically require some foundational engineering experience.",
      "topic": "DevOps",
      "difficulty": "hard"
    },
    {
      "question": "The lecture recommends a learning timeline of 6-8 months to become proficient in which aspect of computer science?",
      "options": [
        "Only Frontend",
        "Only Backend",
        "One specific niche",
        "All four niches simultaneously"
      ],
      "correct_answer": 2,
      "explanation": "The lecture's goal is to equip learners with skills for entry-level job opportunities, suggesting a timeline of 6-8 months to become proficient in one niche.",
      "topic": "Lecture Overview",
      "difficulty": "medium"
    },
    {
      "question": "In the context of AI, the lecture mentions focusing on practical applications and understanding which specific type of models?",
      "options": [
        "Relational Models",
        "Large Language Models (LLMs)",
        "Database Models",
        "Version Control Models"
      ],
      "correct_answer": 1,
      "explanation": "The AI Engineering Curriculum section of the lecture notes emphasizes understanding Large Language Models (LLMs) and their underlying architecture.",
      "topic": "Artificial Intelligence (AI)",
      "difficulty": "medium"
    },
    {
      "question": "Which of the following niches is described as having scarce entry-level roles and often requiring prior experience in other engineering roles?",
      "options": [
        "Fullstack",
        "DevOps",
        "AI",
        "Web3"
      ],
      "correct_answer": 1,
      "explanation": "DevOps is presented as harder to get hired for as an entry-level role, with growth often coming from transitions from other engineering fields.",
      "topic": "DevOps",
      "difficulty": "easy"
    },
    {
      "question": "Which technology is central to Web3 development, involving the learning of blockchains, cryptography, and smart contracts?",
      "options": [
        "Express.js",
        "Docker",
        "Web3",
        "Prisma"
      ],
      "correct_answer": 2,
      "explanation": "Web3 development is defined as involving learning about blockchains, cryptography, smart contracts, and decentralized applications.",
      "topic": "Web3",
      "difficulty": "easy"
    },
    {
      "question": "What is the purpose of Containerization (Docker) in the context of DevOps, as implied by its inclusion in the key concepts?",
      "options": [
        "Developing frontend user interfaces",
        "Managing and deploying applications and infrastructure",
        "Writing smart contracts for blockchains",
        "Building AI agents"
      ],
      "correct_answer": 1,
      "explanation": "Containerization, with Docker being a prime example, is a core DevOps tool used for packaging applications and their dependencies, facilitating consistent deployment and management of infrastructure.",
      "topic": "DevOps",
      "difficulty": "hard"
    },
    {
      "question": "What is a popular Node.js framework mentioned for building HTTP servers in backend development?",
      "options": [
        "Prisma",
        "Express.js",
        "Bun.js",
        "MongoDB"
      ],
      "correct_answer": 1,
      "explanation": "Express.js is a popular Node.js framework recommended for building HTTP servers in backend development.",
      "topic": "Fullstack Development",
      "difficulty": "easy"
    },
    {
      "question": "Which programming language's architecture and asynchronous aspects are highlighted as potentially challenging for beginners in the Fullstack roadmap?",
      "options": [
        "HTML",
        "CSS",
        "JavaScript",
        "SQL"
      ],
      "correct_answer": 2,
      "explanation": "The Fullstack Development roadmap points out that the architecture of JavaScript and Async.js can be challenging for beginners and suggests revisiting them.",
      "topic": "Fullstack Development",
      "difficulty": "medium"
    },
    {
      "question": "What is the primary role of an ORM (Object-Relational Mapper) like Prisma in Fullstack development?",
      "options": [
        "Simplifying frontend styling",
        "Managing database interactions from the backend",
        "Improving website performance",
        "Securing smart contracts"
      ],
      "correct_answer": 1,
      "explanation": "ORMs like Prisma facilitate interaction between the application code (often backend) and relational databases, simplifying database queries and operations.",
      "topic": "Fullstack Development",
      "difficulty": "hard"
    },
    {
      "question": "What key concept related to AI is highlighted in the lecture, particularly in the context of building agents and understanding underlying architecture?",
      "options": [
        "Blockchain Technology",
        "Containerization",
        "Large Language Models (LLMs)",
        "HTTP Protocol"
      ],
      "correct_answer": 2,
      "explanation": "The AI Engineering Curriculum section specifically mentions focusing on an understanding of Large Language Models (LLMs) and their underlying architecture.",
      "topic": "Artificial Intelligence (AI)",
      "difficulty": "hard"
    },
    {
      "question": "What is Prisma, mentioned in the Fullstack Development roadmap?",
      "options": [
        "A frontend framework",
        "A JavaScript runtime",
        "An Object-Relational Mapper (ORM)",
        "A database system"
      ],
      "correct_answer": 2,
      "explanation": "Prisma is listed as an example of an Object-Relational Mapper (ORM) within the database section of the Fullstack Development roadmap.",
      "topic": "Fullstack Development",
      "difficulty": "medium"
    },
    {
      "question": "Which of the following is NOT listed as a core technology in the Fullstack Development roadmap?",
      "options": [
        "HTML",
        "CSS",
        "Docker",
        "JavaScript"
      ],
      "correct_answer": 2,
      "explanation": "Docker (Containerization) is a key concept in DevOps, not a core technology listed in the Fullstack Development roadmap.",
      "topic": "Fullstack Development",
      "difficulty": "medium"
    },
    {
      "question": "What is a faster JavaScript runtime mentioned as a modern enhancement for Fullstack development?",
      "options": [
        "Node.js",
        "Express.js",
        "Bun.js",
        "Deno"
      ],
      "correct_answer": 2,
      "explanation": "Bun.js is mentioned as a faster JavaScript runtime that can be used as a modern enhancement in Fullstack development.",
      "topic": "Fullstack Development",
      "difficulty": "easy"
    },
    {
      "question": "What is a primary benefit of focusing on project-based learning as emphasized in the lecture?",
      "options": [
        "It reduces the need for theoretical knowledge",
        "It helps solidify understanding and demonstrate skills",
        "It is a faster way to learn than reading documentation",
        "It guarantees immediate job placement"
      ],
      "correct_answer": 1,
      "explanation": "The lecture emphasizes project-based learning to 'solidify understanding and demonstrate skills in each niche,' making it practical and job-market relevant.",
      "topic": "Project-Based Learning",
      "difficulty": "hard"
    },
    {
      "question": "What is a potential financial investment mentioned for learning DevOps, related to cloud environments?",
      "options": [
        "$10",
        "$50",
        "$100",
        "$500"
      ],
      "correct_answer": 2,
      "explanation": "The lecture notes mention that learning DevOps requires some financial investment for cloud environments, estimated at $100.",
      "topic": "DevOps",
      "difficulty": "medium"
    },
    {
      "question": "What is a key characteristic of the AI niche as described in the lecture, beyond just general machine learning?",
      "options": [
        "Focus on frontend frameworks",
        "Emphasis on building agents and understanding LLMs",
        "Development of decentralized applications",
        "Infrastructure management"
      ],
      "correct_answer": 1,
      "explanation": "The AI niche is described as focusing on 'applied machine learning and building agents, with an understanding of LLMs and their underlying architecture.'",
      "topic": "Artificial Intelligence (AI)",
      "difficulty": "hard"
    },
    {
      "question": "Which of these is a modern enhancement mentioned for JavaScript and Node.js in the Fullstack Development roadmap?",
      "options": [
        "HTTP Protocol",
        "MongoDB",
        "Bun.js",
        "Express.js"
      ],
      "correct_answer": 2,
      "explanation": "Bun.js is listed as a faster JavaScript runtime and is considered a modern enhancement in the Fullstack Development roadmap.",
      "topic": "Fullstack Development",
      "difficulty": "medium"
    },
    {
      "question": "Which database is suggested as simple to learn for beginners in Fullstack development?",
      "options": [
        "PostgreSQL",
        "MySQL",
        "MongoDB",
        "SQLite"
      ],
      "correct_answer": 2,
      "explanation": "MongoDB is highlighted as a database that is simple to learn for beginners in Fullstack development.",
      "topic": "Fullstack Development",
      "difficulty": "easy"
    },
    {
      "question": "Which of the following is NOT listed as a core frontend technology for Fullstack development?",
      "options": [
        "HTML",
        "CSS",
        "JavaScript",
        "Docker"
      ],
      "correct_answer": 3,
      "explanation": "Docker is a DevOps tool, not a core frontend technology for Fullstack development which includes HTML, CSS, and JavaScript.",
      "topic": "Fullstack Development",
      "difficulty": "easy"
    },
    {
      "question": "The lecture suggests dedicating approximately how much time to mastering the basics of HTML and CSS in the Fullstack roadmap?",
      "options": [
        "2 months",
        "1 week",
        "6-8 months",
        "2 days"
      ],
      "correct_answer": 1,
      "explanation": "The Fullstack Development roadmap indicates that learners should spend about a week on the basics of HTML and CSS.",
      "topic": "Fullstack Development",
      "difficulty": "medium"
    },
    {
      "question": "For Fullstack development, what is the recommended time investment for mastering the basics of HTML and CSS?",
      "options": [
        "6-8 months",
        "2 months",
        "A significant time investment",
        "About a week"
      ],
      "correct_answer": 3,
      "explanation": "The lecture's Fullstack Development Roadmap section specifies spending 'about a week on basics' for HTML and CSS.",
      "topic": "Fullstack Development",
      "difficulty": "hard"
    },
    {
      "question": "What is the recommended learning timeline to become proficient in one niche, according to the lecture?",
      "options": [
        "1-2 months",
        "3-4 months",
        "6-8 months",
        "1-2 years"
      ],
      "correct_answer": 2,
      "explanation": "The speaker suggests a learning timeline of 6-8 months to become proficient in one of the discussed niches.",
      "topic": "Lecture Overview",
      "difficulty": "easy"
    },
    {
      "question": "What concept is crucial for managing infrastructure, deployment, and operations within the DevOps niche?",
      "options": [
        "Blockchain",
        "Smart Contracts",
        "Containerization",
        "LLMs"
      ],
      "correct_answer": 2,
      "explanation": "Containerization, exemplified by tools like Docker, is a key concept for managing infrastructure and deployment in DevOps.",
      "topic": "DevOps",
      "difficulty": "medium"
    },
    {
      "question": "What is a concept in Web3 development that involves writing self-executing code on a blockchain?",
      "options": [
        "HTTP Protocol",
        "Smart Contracts",
        "Async.js",
        "ORMs"
      ],
      "correct_answer": 1,
      "explanation": "Smart Contracts are a fundamental concept in Web3 development, referring to self-executing code on a blockchain.",
      "topic": "Web3",
      "difficulty": "easy"
    },
    {
      "question": "What core technology is fundamental for building HTTP servers in backend development, according to the Fullstack roadmap?",
      "options": [
        "MongoDB",
        "Express.js",
        "TypeScript",
        "HTML"
      ],
      "correct_answer": 1,
      "explanation": "The Fullstack Development roadmap highlights Express.js as a popular Node.js framework for building HTTP servers, emphasizing significant time investment for learning it.",
      "topic": "Fullstack Development",
      "difficulty": "medium"
    },
    {
      "question": "According to the lecture, what is the recommended starting niche for complete beginners in computer science skills?",
      "options": [
        "DevOps",
        "AI",
        "Fullstack Development",
        "Web3"
      ],
      "correct_answer": 2,
      "explanation": "The speaker recommends Fullstack development for complete beginners due to its relative simplicity and commoditization.",
      "topic": "Fullstack Development",
      "difficulty": "easy"
    }
  ]
}